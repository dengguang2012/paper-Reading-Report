---
layout: post
title: spark
categories:
- paper
tags:
- technology
- 
---

##弹性分布式数据集：内存内的集群计算的容错抽象

原文相关信息：

Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing

Matei Zaharia, Mosharaf Chowdhury, Tathagata Das, Ankur Dave, Justin Ma,Murphy McCauley, Michael J. Franklin, Scott Shenker, Ion Stoica

University of California, Berkeley

发表于nsdi 12

邓志会 2015210926

元东 2015210938

现有的集群计算框架(如MapReduce)都提供访问集群计算资源的抽象，但缺少利用分布式内存的抽象。这使得它们不能高效的适用于一类重要的新兴应用，这类应用的特点是复用跨多个计算过程的中间结果。
数据复用有两种典型的应用场景：迭代机器学习和图算法；交互式数据挖掘，在相同的数据子集上运行多次即席查询(ad-hoc query)；作者提出了一个可以使得程序员在大的集群中按照容错的方式执行内存计算的分布式内存抽象-弹性分布式数据集（RDDs）。
RDDs的灵感来源于现在两种类型计算框架低效问题，迭代计算和交互方式的数据挖掘工具。在这两种情况下，保持数据在内存中可以由大小顺序改善性能。为了有效达到容错，RDDs提供了一个基于粗粒度而非细粒度变换的限制形式的共享内存。然而，
作者指出RDDs在捕获广泛类别的计算中表现的足够，包括近来的专门的编程模型迭代工作，例如Pregel，和新的应用不能捕获的模型。作者已经在一个叫做Spark系统中实现了RDDs，通过一系列的用户应用基准进行了评估。

### 背景介绍

集群计算框架，比如MapReduce和Dryady 已经被广泛的采取进行大规模数据分析。这些系统让用户使用一系列的高级运算写并行计算，不用担心分布式计算容错。数据复制，磁盘I/O和序列化需要大量时间开销，主导了应用的执行时间。因此作者提出一种称为resilient distributed datasets(RDDs)的抽象，在广泛的应用中能有效实现数据复用。RDDs是容错的、并行数据结构，能让用户显式的将计算中间结果保持在内存中；控制它们的分区以优化数据位置；使用丰富的操作符操作它们。设计RDDs的主要挑战是定义一个能够提供有效容错的编程接口。RDDs提供了基于粗粒度转换的接口(例如：map、filter、join)，这些转换将相同的操作应用到许多数据项上。这也体现了RDDs的两个显著特点：并行——转换将相同的操作应用到许多数据条目上。容错——通过记录用在数据集上的转换(数据沿袭)实现容错。如果RDD的一个分区丢失，RDD有足够的信息知道它是如何从其他RDD推导过来的，从而可以重新计算得到该分区。因此丢失的数据能被恢复，而且通常很快，不需要高昂的数据复制操作。
即使现有框架提供了很多对于访问集群计算资源的抽象，他们缺乏利用分布式内存的抽象，这使得它们对于一些重要新兴应用低效：那些在多个计算中重利用中间结果，数据重用普遍在多个迭代机器学习和图算法中，包括pagerank ,kMeans聚类和logistic回归，另一个编译用例是交互式数据挖掘，用户运行多个临时查询在同一个数据子集中。不幸运的是，在大多数现有框架中，唯一的在计算之间重用数据的方式是把它写到外部持久存储系统，例如一个分布式文件系统。这招致由于数据复制大量的负担，磁盘输入输出，和序列化，会占用大量应用执行时间。
意识到这个问题，研究者已经为一些需要数据重用的应用开发了专门的框架。例如Pregel是一个保持内存中间数据迭代图计算的系统，Haloop 提供迭代的MapReduce接口。然而，这些框架之支持特定的计算模式。
这篇论文提出了一个新的抽象接口称为弹性分布式数据集，它使得可以在广泛应用中高效数据重用，RDDs容错，并行数据结构，让用户明确保持内存中间结果，控制分区优化数据安置，使用富余操作集合操作他们。

设计RDDs主要挑战在于定义一个编程接口可以提供高效率容错。现有的集群内存存储接口，比如分布式共享内存，键值对存储，数据库和Piccolo，提供一个基于细粒度更新的接口到可变状态上。有了这个接口，提供容错性唯一方式是在机器之间复制数据或者在机器之间记录更新到日志中。两种方法对于数据密集工作量开销都很大，当它们需要复制大量的数据在集群网络中，集群的带宽远远低于RAM，这导致大量的存储负担。

对比这些系统，RDDs提供了一个基于粗粒度转换提供了接口把同样的操作应用到许多数据项上，这允许它们高效的提供容错性通过把变换记录到日志用来构建数据集而不是真实数据。如果一个RDD分区丢失，RDD有足够的信息关于它如何继承其他的RDDs来重新只计算那个分区。因此，丢失数据可以常常很快被恢复，不需要复制开销时间。

虽然基于粗粒度变换接口可能刚开始像是被限制的，RDDs是很好的适于许多并行应用，因为这些应用适用于对多个数据项做同样的操作。确实，这也显示RDDs可以高效的解释许多集群编程模型，已经被提出为单独的系统，包括MapReduce，DryadLINQ，SQL，Pregel和Haloop ,和这些系统没有抓住的应用，比如交互式数据挖掘。RDDs能够容纳计算需要先前只是介绍新的框架。

### 弹性分布式数据库

这个部分提供RDDs的概述。作者首先定义了RDDs，介绍了编程接口Spark，然后比较了RDDs和粗粒度共享内存抽象，最后作者讨论了RDD模型的局限性。

RDD抽象形式上，RDD是一个只读的，分割集合的记录。RDDs可以只通过决定操作在持久存储或者其他的RDDs上面被创建。我们把这些操作变换把它们和其他RDDs上面的操作进行区分。变换的例子包括map,filter和join。

RDDs不需要一直被实现。反而，RDD有关于它如何继承其他的数据集充足的信息来从持久存储数据中计算它的分区。这是一个很强大的特性，本质上，一个程序不能参考一个RDD，它不能冲失败之后再重建。
一个RDD是一个只读的，分区的记录集合。RDDs只能通过对(1)稳定存储上的数据或(2)其他RDDs的确定操作来创建。RDDs不需要在所有时间都是具体存在的。因为一个RDD有足够的信息知道它如何从其他的数据集推导出来(它的沿袭)，最终从稳定存储上的数据计算出它的分区。这是一个强大的特性：本质上，程序不会引用到失效后无法重构的RDD。用户能控制RDDs的两个方面
持久化(persistence)：指定要复用的RDDs并选择存储策略(如存储在内存)
分区(partitioning)：要求RDDs基于每条记录中的key将元素分配到不同的机器。

RDDs最适合对数据集的全部元素进行相同操作的批处理应用。在这种情形下，RDDs能有效的将每个转换记为沿袭图谱中的一步，并且能恢复丢失的分区而不需要记录大量数据。RDDs不适合对共享状态做异步细粒度更新的应用，如web应用的存储系统，增量web爬虫。RDDs的目标是提供对批处理分析的有效编程模型。

### spark编程接口

Spark通过一个集成语言类似DryadLINQ和FlumeJava的API暴露RDDs,每个数据集表示为一个对象和使用这些对象方法涉及转换 。程序员通过持久存储数据转换定义一个或者更多的RDDs。它们那时会实际上使用这些RDDs，这些操作会返回一个值到应用中或者导出数据到一个存储系统，实际例子包括count,collect和save。像是DryadLINQ ,Spark首次计算RDDs，它们在实际中被使用，因此它会管道化转换。

此外，程序员会调用一个persist方法来表明他们在未来操作中想要重用，Spark保持持续RDDs默认在内存中，但是它会使得它们溢出磁盘如果没有足够的RAM。用户会请求其他的持续策略，比如只把RDD存储在磁盘上面或者在机器之间复制，通过持续标志位。最后，用户会设置一个持续优先级在每个RDD上来指定哪个内存数据应该首先溢出到磁盘。

###例子：控制台日志挖掘

假设一个网络服务经历了错误并且有操作想要从hdfs文件系统中搜索tb日志，使用spark,操作会通过一系列的节点和交互式的查询从日志向RAM只加载错误消息。它将首先编码Scala如下：

<img src="https://github.com/dengguang2012/paper-Reading-Report/blob/master/illustraction/30.png" style="width: 50%; height: 50%"/>​


	lines = spark.textFile("hdfs://...")
	errors = lines.filter(_.startsWith("ERROR"))
	errors.persist()

	第一行定义了一个RDD支持的HDFS 文件，第二行继承了从RDD的过滤器，第三行请求错误在内存保持使得可以通过查询共享。

	errors.count()

	用户可以在RDD 上面执行更远的转换并且使用结果

	// Count errors mentioning MySQL:
	errors.filter(_.contains("MySQL")).count()
	// Return the time fields of errors mentioning
	// HDFS as an array (assuming time is field
	// number 3 in a tab-separated format):
	errors.filter(_.contains("HDFS"))
	.map(_.split('\t')(3))
	.collect()

在第一个操作柏涵错误运行之后，Spark将会存储内存错误分布，极大地加速了下面计算。意识到基本的RDD，行不被加载到RAM中国i部分，这不是想要的，因为错误消息只是数据的一部分。

最后，为了图示化我们的模型如何达到容错性，作者在第三个查询中展示了RDDs的折线图。在这个查询中，作者开始于错误，应用滤波器并且在运行一个集合之前映射。Spark调度将管道化后面的两个转变并且发送一系列任务来计算它们到节点并保持缓存区域错误，此外，如果部分错误丢失，Spark通过应用滤波器在相关的部分行中重建。

<img src="https://github.com/dengguang2012/paper-Reading-Report/blob/master/illustraction/31.png" style="width: 50%; height: 50%"/>​

###RDD模型的优势

为了了解RDDs作为分布式内存抽象的优势，作者比较了它和分布式共享内存。在DSM系统，应用程序在全局地址空间的任意位置读和写。注意在此定义下，作者包含了不仅是传统共享内存系统还包括应用做粗粒度写来分享状态的系统，包括Piccolo，提供一个共享的DHT和分布式数据库。DSM是一个通用抽象。RDDs和DSM主要的不同在于RDDs只会通过粗粒度转换来创建，然而DSM允许读和写每个内存位置。这限制RDDs到应用程序执行bulk写,但是允许更多的高效率容错。特别的，RDDs不需要导致浮点检查开销，它们会使用家系来恢复。此外，只有丢失分区的RDD需要在失败情况下被重复计算，它们会在不同节点并行重复计算，不必回滚整个程序。

RDDs的第二个优势是它们不变的本质使得系统通过运行像在MapReduce中的备份一样缓和慢的节点。备份任务难以用DSM实现，像两个拷贝的任务能访问相同的内存区域和干涉相互的更新。

### Spark编程接口

Spark通过类似在Scala 中DryadLINQ一个整合语言的API提供RDD抽象，一种java虚拟机静态类型的函数式编程语言。我们选择了Scala由于其结合简洁（便于交互使用）和效率（由于静态类型）。然而，没有关于RDD的抽象需要功能性的语言。

要使用Spark，开发人员编写一个驱动程序连接到一堆worker集群，如图2所示。驱动程序定义一个或多个RDDS并在他们上面调用动作。驱动程序上的Spark代码还可以跟踪RDDs的谱系。worked是长生命周期的过程，可以在操作中存储RAM RDD分区。

<img src="https://github.com/dengguang2012/paper-Reading-Report/blob/master/illustraction/32.png" style="width: 50%; height: 50%"/>​

正如我们在日志挖掘实例中显示的那样，用户提供的参数RDD操作如map的传递闭包（函数式）。Scala代表每个闭包为java对象，和这些对象可以被序列化通过网络并加载到另一个节点。Scala也存在闭包中绑定的任何变量作为字段java对象。例如，可以编写代码var x = 5；RDD.map（+ x）对于RDD每个元素加5。RDDS本身是静态类型的对象，参数化的元素类型。例如，RDD 是一个整数方法。然而，我们的大部分示例省略类型因为Scala支持类型推理。虽然我们在Scala暴露RDDS方法从概念上讲很简单，解决问题Scala的闭合对象使用反射也需要更多的工作，使Spark使用Scala解释器有用。尽管如此也没有修改Scala编译器。

<img src="https://github.com/dengguang2012/paper-Reading-Report/blob/master/illustraction/33.png" style="width: 50%; height: 50%"/>​

表2列出了主要的RDD变换和Spark中可用的操作。作者给每个操作取名，显示方括号中的类型参数。回忆这种转换是定义一个新的RDD，而行动推出计算返回一个值的程序或写数据到外部存储。注意，某些操作，如连接，只可使用在RDDs键值对。还有，功能名字的选择相匹配的在Scala其他API和其他功能性语言。比如是一对一的映射，而flatmap映射每个输入值到一个或多个输出（类似于MapReduce的map）。除了这些操作 ，用户可以要求RDD持久。此外，用户可以得到一个RDD的分区的顺序，这是由一个分区类代表的，并根据它来划分另一个数据集。操作如groupbykey，reducebykey和自动排序结果在哈希范围划分RDD。

###代表RDDs 

提供RDDs作为一种抽象的一个挑战是选择一个可以跟踪的跨越广泛的转换表示谱系。最理想的是一个系统实施提供丰富的可能的一组转换运算符RDDs，让用户使用任意的方法组成。我们为促进这些目标提出了一个简单的基于图形的表示的RDDS。已经在Spark使用了这个表示支持广泛的转换不对于每个添加特殊逻辑的调度程序，大大简化了系统设计。

简而言之，作者提出通过一个共同的接口代表每个RDD，公开五条信息：一组分区，它是数据集的原子碎片；一套父亲节点RDDS依赖；一种基于其父母的数据集的计算函数；关于它的分区方案和数据安置的元数据。例如，一个RDD代表了HDFS文件有一个分区，每个文件块都有一个分区，并且知道哪台机器在阻塞中。同时，结果操作这个RDD map具有相同的分区，但应用map计算时的父节点数据的映射函数。最有趣的问题在设计这个接口是怎样代表RDDS之间的依赖关系。作者发现它既有足够的和有用的分类依赖成2种类型：窄的依赖关系，在那里每个父RDD分区最多由一个子节点的RDD分区使用，宽的依赖关系，在多个子分区可能取决于它。例如，map导致一个狭窄的依赖，而加入导致宽依赖（除非父节点是哈希分区）。这种区别是有用的，原因有两点。首先，窄依赖关系考虑在一个集群中的流水线执行的节点，可以计算所有的父分区。相比之下，广泛依赖需要从所有父分区中可用的数据并将在节点上使用mapreduce类是操作。二，节点故障之后的恢复与狭义的依赖关系是更有效的，因为只有失去的父分区需要重新计算，他们可以在不同节点上的并行计算。相反，在一个具有广泛依赖关系的谱系图，一个单一的失败节点可能会导致一些分区的损失一个RDD的祖先，需要完全重新执行。这种常见的接口为RDDS成为可能在小于20的Spark中实现绝大多数的转换代码行。事实上，甚至新的Spark用户已经实施新的转换（例如，采样和各种类型的联接）。

###实现

我们已经使用约14000行的Scala实现了Spark。该系统运行在使用群集管理器Mesos，让它与Hadoop资源共享，MPI和其他应用程序。每一个Spark运行一个单独的目标应用，有自己的驱动和workers，这些应用程序之间的资源共享是由Mesos处理。

Spark可以从任何Hadoop输入资源中读取数据，使用Hadoop已有的输入插件APIs， Spark 的调度使用了代表的RDDs，并且运行一个没有修改版本的Scala。调度考虑了那个分区的持久RDDs在内存中可以被访问，不管何时一个用户运行动作在一个RDD上面，调度检查RDD的谱系图来构建一个DAG执行。每个阶段包含许多流水线变换。Spark调度器使用上一节描述的RDDs的表示。当用户对一个RDD运行action操作(如count或save)时，调度器检查RDD的沿袭图谱，然后建立stages的DAG图来执行。每个stage包含尽可能多的窄依赖流水式转换。stages的边界是需要宽依赖的shuffle操作，或任何已经计算出的分区，这样可以省去从父RDD开始的计算。调度器启动任务从每个stage来计算缺失的分区直到计算出目标RDD。


Scala中包括一个交互式shell相似Ruby和Python。给定的低延迟到达内存数据中，我们想让用户以交互方式运行从解释器到大数据集的查询。scala解释器通常是通过编译一类由用户输入的每一行，将其装入JVM，并调用一个函数，它。这一类包括一个单例对象包含变量和函数，并在初始化时运行该行的代码方法。例如，如果用户编码x为5紧接着println（x），解释器定义了一个类叫Line1包含X和导致第二行编译println（Line1.getinstance() .x）。
Spark提供了三个选项，用于存储的持久性RDDs：在存储器中存储的java对象序列化，在内存中存储序列化的数据，和硬盘存储。第一个选项提供最快的性能，因为java虚拟机可以原生访问每个RDD元。第二个选择让用户选择一个比java对象图表示更高效的内存，当空间是有限的，在成本较低的性能。第三个选择是用来在RDDs太大保持在内存中而重新计算每个使用昂贵的。
调度器基于数据的局部性分配任务给机器。如果一个任务需要处理的分区在一个节点的内存中，我们把这个任务发送到那个节点。否则，如果任务处理的分区，其对应的RDD提供首选位置(如HDFS文件)，我们就把任务发送到这些首选位置。对于宽依赖(如shuffle依赖)，我们将中间结果具体化到持有父分区的节点上以简化故障恢复，与MapReduce具体化map输出很相似。如果任务运行失败，只要它的stage的父stage仍然可用，就在其他节点上重新运行任务。如果一些stages变得不可用了，我们重新提交任务来计算缺失的分区。尽管可以直接复制RDD的沿袭图谱，但我们还是不能容忍调度器失效。
解释器集成

Scala包含一个类似于Ruby和Python的交互式shell。可以低延迟的获取内存中的数据，能让用户从解释器交互式地运行Spark来查询大数据集。用户在Scala解释器中输入的每行语句被编译成一个类，然后载入到JVM，并在上面调用函数。这个类包含单例对象，单例对象包含语句中的变量或函数，并在初始化方法中运行语句。我们在Spark中对解释器做了两个改变：

Class shipping: 让worker节点拉取每行语句对应类的字节码，让解释器通过HTTP服务这些类。
Modified code generation: 正常情况下，每行语句创建的单例对象通过其对应类的静态方法进行访问。这意味着如果要序列化一个闭包时，它引用了前面行中定义的变量，如上例中的Line1.x，Java不会通过对象图追溯来传输具有x的Line1实例。因此worker节点不会收到x。我们修改代码生成逻辑来直接引用每行对象的实例。
下图说明了Spark解释器如何将用户输入的两行代码转换为Java对象。

<img src="https://github.com/dengguang2012/paper-Reading-Report/blob/master/illustraction/35.png" style="width: 50%; height: 50%"/>​

对于其中的内存管理，Spark提供三种可选的RDD持久化存储策略：(1)以反序列化的Java对象形式存储在内存中；(2)以序列化的数据存储在内存中；(3)存储在磁盘上。第一种提供最快的读取性能，因为Java虚拟机可以原生地访问每个RDD元素。第二种让用户在空间受限的时候，以损失较低性能的代价，选择比Java对象图更加存储高效的表示。第三种适用于RDD太大而无法维持在内存中，但每次使用重新计算代价又非常大的情况。为了管理有限可用的内存，在RDDs的级别使用LRU淘汰策略。当计算出一个新RDD分区却没有足够的空间存储它时，淘汰最近最少访问RDD的一个分区。这样就保持旧的分区在内存中以防止来自同一个RDD的分区循环的进出内存。其中重要性在于大多数操作都是在整个RDD上运行任务，因此已经在内存中的分区很可能将来还会被用到。

###评测

评测了Spark和RDDs在一系列Amazon Ec2实验上，和用户应用基准。整体上显示，Spark比Hadoop在迭代机器学习和图应用上超越20×。这个加速来自避免了输入输出和通过存储数据在内存中作为java对象反序列化的开销。
由用户执行和扩展的很好的应用。特别的，我们使用Spark加速分析报告比运行在Hadoop上面快出40×。
当有节点失效，Spark会通过丢失的RDD分区进行快速重建。
Spark会被用来查询1tb数据集交互延迟在5-7s。