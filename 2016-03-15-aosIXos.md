---
layout: post
title: IX
categories:
- technology
tags:
- technology
- 
---

##一个受保护的高吞吐量低延迟网络数据处理操作系统 阅读报告

### 背景

传统观点竞争网络需求，譬如小消息高速率分组和毫秒级别的延迟是在内核之外用户级别网络栈最好的解决方案。IX实在保存已有的内核保护下的已经有的优点情况下。
ix使用硬件虚拟化来区分内核网络处理的管理和调度。数据平面架构建立在本地零拷贝的API之上，通过指定硬件线程和网络队列数据到数据面为带宽和延迟进行了优化，通过减少相关交通和多核同步来处理有界批量完成的数据。
这些要求在今天的数据中心并不少见（如关键值存储）每一个环节的懈怠延迟效应的多个请求的分布式计算模型。，IX相比linux在吞吐量和点对点的延迟上有很好的提升。

首先，在如今的数据中心应用比如搜索、社交网络，电子商务平台对于系统软件都有很高的要求。单独一个应用包含了很多的软件服务，部署在不同的服务器上，使得对于高性能io流的堆栈有很高的需求，对于小消息有很高的包速率，
对于请求毫秒级要求的反应时间，另外对于安全模式也有很高的要求，但是传统系统往往是矛盾的，一些系统忽略了内核在用户层次上面实现网络栈，但性能不好。IX是一个高吞吐量，低延迟，安全而资源效率高的操作系统。
IX数据中心允许网络栈对带宽和延迟进行优化，它的架构建立在从高性能中间件的经验指导下，如防火墙，负载均衡器，以及软件路由器。IX分离控制平面，其负责系统配置和粗粒度资源应用程序之间的配置，
从运行网络协议栈和应用的dataplanes运行数据平面内核，并在不同的应用保护水平和控制平面中隔离数据平面。在我们的实施中，控制平面是完整的Linux内核和运行在保护状态的dataplane，在专用硬件线程基于库的操作系统中。
大规模化数据中心应用带来了独特的挑战：系统软件和网络堆栈：微秒延迟，要启用大量经常互动的服务，而不会影响用户经历整体延迟，由于每个用户的请求往往涉及数百台服务器，我们还必须考虑的RPC请求跨数据中心的延迟。

高分组速率：这些请求很多时候构成一个的各种服务之间的答复
数据中心的应用程序是相当小的。在Facebook的memcached的服务，绝大多数请求使用密钥长度小于50字节，并且每个节点可以扩展到服务每秒百万的请求。

###原理

保护：由于多个服务通常共享公共和私人的数据中心服务器，所以需要在应用程序之间进行隔离。使用内核，或基于超级指令的网络协议栈在很大程度上解决了上述问题。
一个值得信赖的网络堆栈可以防火墙应用程序，强制访问控制列表（ACL），以及实施带宽计量限制器等。
资源效率：数据中心应用负载由于昼夜模式用户流量显著变化，理想的是，每一个服务节点将使用最少资源（核心，存储器，或IOPS）需要满足包速率和尾部等待时间要求。
剩余的服务器资源可以分配给其它应用或放置成用于能量低功率模式来提高效率。现有的操作系统能够支持这样的资源使用策略。
然而如今的商业操作系统一直在非常不同的硬件设计的假设下面设计的。内核调度，网络API和网络协议栈是在多个应用的假设下设计的，它们共享单个处理核，包到达间隔时间比中断延迟和系统调用高出许多倍。
缓冲和同步的开销需要灵活，精细的调度的应用程序支持,以提高核心CPU和内存系统的开销，这限制了吞吐量。随着服务之间的请求的数据中心应用层通常由小分组，共同NIC硬件优化，如TCP分段和接收端的聚结，有数据包率的边际影响。
由于商业内核的网络栈不能利用硬件资源丰富性的优势，提出了若干替代方法，比如用户空间网络堆栈，Alternatives to TCP，Alternatives to POSIX API，OS enhancements。

<img src="http://7xrmn9.com1.z0.glb.clouddn.com/aos11.png" style="width: 50%; height: 50%"/>​
 
对于IX设计的方法，许多中间件dataplanes采用的设计原则与传统的操作系统不同。商业操作系统从应用程序本身解耦协议处理，以便提供调度和流量控制的灵活性。
例如，内核依赖于设备和软中断应用在程序协议处理的上下文中切换。同样，内核网络堆栈将产生TCP ACK并且滑动接受窗口，即使在应用程序不消耗窗口数据，到了最多的程度。
其次，中间件dataplanes为了免同步操作优化，这使得在许多内核进行了很好地扩展。网络流量分布在不同的队列中，通过常流量的hash和包处理不需要同步的通常情况。
作为对比，传统操作系统往往在很大程度上依赖交通的连贯性并构造锁等同步形式。
控制和数据链路的分隔和保护，IX分隔内核的控制功能，负责从数据平面资源配置，调度，和监测，它运行网络协议栈和应用逻辑。
运行自适应分批完成，IX 数据平面运行完成接收和传送数据包的所有阶段，使得内核态的协议处理和用户态的应用程序逻辑在定义好的变换点很好地交织。
有明确的流量控制的native,zero-copy api，我们不公开或者模拟网络的POSIX API。相反，数据面内核和应用程序在存储中使用消息来协调过渡点的通信。
一致网络流，免除同步处理，我们使用了带有接收端缩放多队列的NICs网卡提供了一致网络流到来通路的哈希，并且分导到不同的硬件队列中。
dataplane不同于典型的内核，他特指高性能网络IO，只运行单个程序，类是一个库操作系统但是内存是分割单独，此外 dataplan还提供很多熟悉的内核层次服务。

###测试评估和相关工作

测试使用了IX和Linux  mTCP做了对比，带宽延迟都要更优秀，究其原因是把网络工作栈是现在一个保护的操作系统内核中，并能够对于很多benchmark提供传输线级别性能。但是IX对于动态运行时没有做优化。
相关工作比如Hardware Virtualization Arrakis使用硬件虚拟化分隔IO数据层和控制层，对控制层，网络堆栈和应用程序进行分离
